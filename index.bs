<!DOCTYPE html>
<meta charset="utf-8">
<title>Considering A W3C Standard For Stateful Serverless</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Nathan Flurry">
<meta name="keywords" content="durable-objects, actor-core, standard, w3c">
<meta name="publication-date" content="2025-03-23">
<meta name="category" content="technical">
<link rel="stylesheet" href="style.css">

<pre class='metadata'>
Shortname: stateful-serverless
Level: 1
Editor: Nathan Flurry
Abstract: This document considers a W3C standard for stateful serverless computing, allowing serverless functions to maintain state across multiple invocations.
Repository: rivet-gg/proposal-stateful-serverless-api
Status: LD
Title: Stateful Serverless API
</pre>

## ServerlessWorker` ## {#serverless-worker}

<img src="./media/serverlessworker.png" alt="Diagram illustrating the architecture of ServerlessWorker with client connections and persistent storage">

`ServerlessWorker` is an API similar to the existing Web Workers API that provides the core functionality of both Cloudflare Durable Objects and Rivet Actors:

1. **Multi-Tenant**: `ServerlessWorker` can serve multiple clients at the same time in realtime.
2. **Message-Based Communication**: Communicates via `postMessage`.
3. **Persistent**: `ServerlessWorkers` run forever. They cannot crash. Implementations of the standard can optionally make workers sleep when there is no activity.
4. **Storage**: `ServerlessWorkers` can store data that persists for ever. Implementations of the standard should design this data to be stored next to compute for optimal read-write performance.
5. **Isolated Execution Context**: Each worker runs in its own isolated environment

### Creating, Initializing, & Addressing `ServerlessWorker`s ### {#creating-workers}

Constructing a `ServerlessWorker` object will mimic the `SharedWorker` API. Passing a `name` parameter to the second constructor argument will let you address a given `ServerlessWorker`. Passing no arguments will give you the same worker.

The `name` is accessible in the global scope of the `ServerlessWorker`.

An example API could look like:

<pre class="example" highlight="js" title="server.js">
export default {
  fetch(req) {
    const worker = new ServerlessWorker("./worker.js");
    // ...
  }
}
</pre>

To resolve with a custom name:

<pre class="example" highlight="js" title="server.js">
export default {
  fetch(req) {
    // ...
    const worker = new ServerlessWorker("./worker.js", `chat-room-${random}`);
    // ...
  }
}
</pre>

To access the name in the worker:

<pre class="example" highlight="js" title="worker.js">
// Worker code can access its name
console.log(self.name);
</pre>

### Terminating `ServerlessWorker`s ### {#terminating-workers}

Add a `terminate` method on the `ServerlessWorker` itself, leave it up to the frameworks to implement destroying. For example:

<pre class="example" highlight="js" title="worker.js">
export default {
  connect(event) {
    self.terminate();
  }
}
</pre>

### Connections & Messages ### {#connections-messages}

`ServerlessWorker` should use ESM-style exports with a `SharedWorker`-like API. This allows the simplicity of request/response & also enables full bidirectional streaming -- like a WebSocket but without the overhead.

<div class="example">
<pre class="example-code" highlight="js" title="server.js">
export default {
  fetch(conn) {
    const workerId = createServerlessWorkerId();
    const worker = new ServerlessWorker("./worker.js", workerId);
    conn.port.postMessage({ action: 'greet', data: 'foo' });
  }
};
</pre>

<pre class="example-code" highlight="js" title="worker.js">
export default {
  connect(conn) {
    const port = conn.ports[0];

    port.onmessage = event => {
      const { action, data } = event.data;

      if (action === 'greet') {
        conn.postMessage({ response: `Stateful serverless received: ${data}` });
      }
    };

    port.onclose = event => console.log('Conn disconnected');
  }
};
</pre>
</div>

### Storage ### {#storage}

Provide a dead simple async structured clone-based KV API and let the platforms provide extra configs for concurrency. For example:

<pre class="example" highlight="js" title="worker.js">
let count = await storage.get("count") || 0;

export default {
  connect(conn) {
  const port = conn.ports[0];

    port.onmessage = async (event) => {
      count += 1;
      await storage.put("count", count);
    };
  }
}
</pre>

### Scheduling ### {#scheduling}

Provide an API similar to Cloudflare's <a href="https://developers.cloudflare.com/durable-objects/api/storage-api/#setalarm">`setAlarm`</a>. For example:

<pre class="example" highlight="js" title="worker.js">
// Set an alarm for 1 day
setAlarm(Date.now() + 86_400 * 1000);

export default {
  alarm() {
    console.log("It's been 1 day");
  }
}
</pre>

### Sleeping & Upgrading & Host Migrations ### {#sleeping-upgrading}

Provide an API similar to Durable Objects `waitUntil`. The provider can decide the maximum duration for this function. For example:

<pre class="example" highlight="js" title="worker.js">
async function doSomethingAsync() {
  // ...
}

waitUntil(doSomethingAsync());
</pre>

### Handling Backpressure ### {#backpressure}

Define an error type that can be used by developers to handle backpressure gracefully.

### Security Model ### {#security-model}

`ServerlessWorker` should rely on the existing work in WinterTC. They are secured via these attributes:

- **Fetch Handler**: Stateful `ServerlessWorker`s are only accessible through the stateless serverless fetch handler defined in WinterTC. This creates a protected gateway where all requests are authenticated and authorized before reaching any `ServerlessWorker`.
- **Isolation Boundaries**: Each `ServerlessWorker` runs in its own isolated environment, similar to Web Workers, preventing cross-worker data access without explicit communication channels.
- **No Direct Network Access**: `ServerlessWorker`s cannot be directly addressed from the public internet. All communication flows through the fetch handler, which can implement rate limiting, validation, and other security controls.

The downside of relying on the fetch handler is that it may restrict who can implement `ServerlessWorker`. For example, there are many container orchestration platforms that may be able to implement the worker part of `ServerlessWorker`, but cannot implement the `fetch` handler. I don't think this is an issue, since including these technologies that don't already comply to WinterTC would make it too broad to be effective.

